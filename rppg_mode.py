#!/usr/bin/env python
# coding: utf-8

# In[68]:


import cv2
import mediapipe as mp
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import json, os, time, re, serial
from collections import deque
from datetime import datetime
from scipy.signal import butter, filtfilt, find_peaks
import matplotlib.pyplot as plt
from IPython.display import clear_output
import time
import subprocess, shutil, platform, threading, os
from pathlib import Path
import tempfile

time.sleep(6)

# --- TTS í´ë” (TTS/ ë˜ëŠ” tts/ ì–´ëŠ ìª½ì´ë“ ) ---
_BASE = Path(__file__).parent.resolve() if "__file__" in globals() else Path.cwd().resolve()
_TTS_DIR = (_BASE / "TTS")
if not _TTS_DIR.exists():
    _TTS_DIR = (_BASE / "tts")
_TTS_DIR = _TTS_DIR.resolve()

def first_existing(*names):
    for n in names:
        p = (_TTS_DIR / n).resolve()
        if p.exists():
            return str(p)
    return None

# ê³ ì • ë©˜íŠ¸ íŒŒì¼ (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìë™ í´ë°±)
AUDIO_END_PREFIX = first_existing("end_prefix.mp3")  # ì˜ˆ: "ì¸¡ì •ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê·  ì‹¬ë°•ìˆ˜"
AUDIO_END_SUFFIX = first_existing("end_suffix.mp3")  # ì˜ˆ: "ì…ë‹ˆë‹¤."
AUDIO_END_FAIL   = first_existing("end_fail.mp3")    # ì˜ˆ: ì‹¤íŒ¨ ë©˜íŠ¸

def play_audio_file(path_str: str) -> bool:
    """ë¸”ë¡œí‚¹ ì¬ìƒ(ê²¹ì¹¨ ë°©ì§€). macOSë©´ afplay ìš°ì„ , ê·¸ ì™¸ playsound."""
    if not path_str or not os.path.exists(path_str):
        return False
    try:
        if shutil.which("afplay"):
            subprocess.run(["afplay", path_str], check=True)
            return True
        else:
            try:
                from playsound import playsound
                playsound(path_str)
                return True
            except Exception:
                pass
    except Exception as e:
        print(f"[AUDIO] play failed: {e}")
    return False

# macOS 'say'ë¥¼ íŒŒì¼ë¡œ í•©ì„± â†’ ë¸”ë¡œí‚¹ ì¬ìƒ(ìˆœì°¨ ë³´ì¥)
PREFER_SAY = (platform.system() == "Darwin" and shutil.which("say") is not None)
SAY_VOICE = "Yuna"   # macOS í•œêµ­ì–´ ê¸°ë³¸ ì—¬ì„± ìŒì„± (ë‚¨ì„± ê¸°ë³¸ ì—†ìŒ)
SAY_RATE  = 190

def tts_say_blocking(text: str, *, voice: str | None = SAY_VOICE, rate: int | None = SAY_RATE) -> bool:
    if not text:
        return False
    if not PREFER_SAY:
        print("[TTS]", text)  # macOSê°€ ì•„ë‹ˆë©´ í”„ë¦°íŠ¸ë¡œ ëŒ€ì²´
        return False
    fd, tmp = tempfile.mkstemp(prefix="tts_", suffix=".aiff")
    os.close(fd)
    try:
        args = ["say", "-o", tmp]
        if voice: args += ["-v", voice]
        if rate:  args += ["-r", str(rate)]
        args.append(text)
        subprocess.run(args, check=True)   # í•©ì„±(ë¸”ë¡œí‚¹)
        ok = play_audio_file(tmp)          # ì¬ìƒ(ë¸”ë¡œí‚¹)
        return ok
    except Exception as e:
        print("[TTS FAIL]", e, "|", text)
        return False
    finally:
        try: os.remove(tmp)
        except: pass

# ===== 9ê°€ì§€ í”¼ë¶€ ì¼€ì´ìŠ¤ íŒŒì¼ ë§¤í•‘ =====
# TTS/ ë˜ëŠ” tts/ í´ë”ì— ì•„ë˜ íŒŒì¼ëª…ì„ ë„£ìœ¼ë©´ ìë™ ì‚¬ìš©ë©ë‹ˆë‹¤.
# íŒŒì¼ì´ ì—†ìœ¼ë©´ ë™ì¼ ë¬¸ì¥ìœ¼ë¡œ TTS í´ë°±í•©ë‹ˆë‹¤.
SKIN9_FILES = {
    # 1~3: ë¶‰ìŒ + ê· ì¼ë„ Good/Mid/Low
    "red_good":  first_existing("rPPG_Red_even.mp3"),
    "red_mid":   first_existing("rPPG_Red_Slight_even.mp3"),
    "red_low":   first_existing("rPPG_Red_Not_even.mp3"),
    # 4~6: ì •ìƒ + ê· ì¼ë„ Good/Mid/Low  (ì •ìƒì¼ ë•ŒëŠ” 'ì •ìƒ' ì–¸ê¸‰ ì—†ì´ ê· ì¼ë„ë§Œ ì•ˆë‚´)
    "norm_good": first_existing("rPPG_Normal.mp3"),
    "norm_mid":  first_existing("rPPG_Normal_Slight_even.mp3"),
    "norm_low":  first_existing("rPPG_Normal_Not_even.mp3"),
    # 7~9: ì°½ë°± + ê· ì¼ë„ Good/Mid/Low
    "pale_good": first_existing("rPPG_Pale_even.mp3"),
    "pale_mid":  first_existing("rPPG_Pale_Slight_even.mp3"),
    "pale_low":  first_existing("rPPG_Pale_Not_even.mp3"),
}

# (ì„ íƒ) ì•ˆë‚´ ì•/ë’¤ì— ë¶™ì¼ í”„ë¦¬/ì„œí”½ìŠ¤ mp3 (ìˆìœ¼ë©´ ì¬ìƒ)
SKIN_PREFIX = first_existing("skin_prefix.mp3")  # ì˜ˆ: "í”¼ë¶€ ìƒíƒœ ìš”ì•½ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
SKIN_SUFFIX = first_existing("skin_suffix.mp3")

# ë¼ë²¨ í‘œì¤€í™” + ê· ì¼ë„ ë²„í‚·
def _normalize_redness(label: str) -> str:
    if not label:
        return "ì •ìƒ"
    if label in ("í™ì¡°", "ë¶‰ìŒ", "Red"):
        return "ë¶‰ìŒ"
    if label in ("ì°½ë°±", "Pale"):
        return "ì°½ë°±"
    return "ì •ìƒ"

def _uniformity_bucket(u: float) -> str:
    # uëŠ” 0~1 (ì´ë¯¸ ì½”ë“œì—ì„œ ê·¸ë ‡ê²Œ ì‚°ì¶œ)
    if u is None:
        return "ë¶ˆê· ì¼"
    if u >= 0.8:
        return "ì¢‹ìŒ"
    elif u >= 0.6:
        return "ì‚´ì§ ë¶ˆê· ì¼"
    else:
        return "ë¶ˆê· ì¼"

def _skin_case_id(red: str, ub: str) -> int:
    table = {
        ("ë¶‰ìŒ","ì¢‹ìŒ"):1, ("ë¶‰ìŒ","ì‚´ì§ ë¶ˆê· ì¼"):2, ("ë¶‰ìŒ","ë¶ˆê· ì¼"):3,
        ("ì •ìƒ","ì¢‹ìŒ"):4, ("ì •ìƒ","ì‚´ì§ ë¶ˆê· ì¼"):5, ("ì •ìƒ","ë¶ˆê· ì¼"):6,
        ("ì°½ë°±","ì¢‹ìŒ"):7, ("ì°½ë°±","ì‚´ì§ ë¶ˆê· ì¼"):8, ("ì°½ë°±","ë¶ˆê· ì¼"):9,
    }
    return table.get((red, ub), 6)  # ëª»ë§ì¶”ë©´ ë³´ìˆ˜ì ìœ¼ë¡œ 6(ì •ìƒ-ë¶ˆê· ì¼)

# ê° ì¼€ì´ìŠ¤ë³„ TTS í´ë°± ë¬¸ì¥ (íŒŒì¼ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
SKIN9_FALLBACK_TEXT = {
    1: "í”¼ë¶€ê°€ ë‹¤ì†Œ ë¶‰ìŠµë‹ˆë‹¤. í”¼ë¶€ ìê·¹ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”. í”¼ë¶€í†¤ì´ ë§¤ìš° ê· ì¼í•©ë‹ˆë‹¤.",
    2: "í”¼ë¶€ê°€ ë‹¤ì†Œ ë¶‰ìŠµë‹ˆë‹¤. í”¼ë¶€ ìê·¹ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”. í”¼ë¶€í†¤ì´ ì‚´ì§ ë¶ˆê· ì¼í•©ë‹ˆë‹¤.",
    3: "í”¼ë¶€ê°€ ë‹¤ì†Œ ë¶‰ìŠµë‹ˆë‹¤. í”¼ë¶€ ìê·¹ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”. í”¼ë¶€í†¤ì´ ë¶ˆê· ì¼í•©ë‹ˆë‹¤.",
    4: "í”¼ë¶€í†¤ì´ ë§¤ìš° ê· ì¼í•©ë‹ˆë‹¤.",
    5: "í”¼ë¶€í†¤ì´ ì‚´ì§ ë¶ˆê· ì¼í•©ë‹ˆë‹¤.",
    6: "í”¼ë¶€í†¤ì´ ë¶ˆê· ì¼í•©ë‹ˆë‹¤.",
    7: "í”¼ë¶€ê°€ ì°½ë°±í•´ ë³´ì…ë‹ˆë‹¤. ì»¨ë””ì…˜ ì €í•˜ë‚˜ ìˆ˜ë©´ ë¶€ì¡±ì¼ ìˆ˜ ìˆì–´ìš”. í”¼ë¶€í†¤ì´ ë§¤ìš° ê· ì¼í•©ë‹ˆë‹¤.",
    8: "í”¼ë¶€ê°€ ì°½ë°±í•´ ë³´ì…ë‹ˆë‹¤. ì»¨ë””ì…˜ ì €í•˜ë‚˜ ìˆ˜ë©´ ë¶€ì¡±ì¼ ìˆ˜ ìˆì–´ìš”. í”¼ë¶€í†¤ì´ ì‚´ì§ ë¶ˆê· ì¼í•©ë‹ˆë‹¤.",
    9: "í”¼ë¶€ê°€ ì°½ë°±í•´ ë³´ì…ë‹ˆë‹¤. ì»¨ë””ì…˜ ì €í•˜ë‚˜ ìˆ˜ë©´ ë¶€ì¡±ì¼ ìˆ˜ ìˆì–´ìš”. í”¼ë¶€í†¤ì´ ë¶ˆê· ì¼í•©ë‹ˆë‹¤.",
}

def _skin_file_key(case_id: int) -> str:
    return {
        1:"red_good", 2:"red_mid", 3:"red_low",
        4:"norm_good",5:"norm_mid",6:"norm_low",
        7:"pale_good",8:"pale_mid",9:"pale_low",
    }[case_id]

def speak_skin_case_9way(redness_label: str, uniformity_val: float):
    """9ê°€ì§€ ì¡°í•© ì¤‘ ë§ëŠ” mp3ë¥¼ ì¬ìƒ(ìˆìœ¼ë©´), ì—†ìœ¼ë©´ ë™ì¼ ë¬¸ì¥ìœ¼ë¡œ TTS."""
    red = _normalize_redness(redness_label)
    ub  = _uniformity_bucket(uniformity_val)
    cid = _skin_case_id(red, ub)
    key = _skin_file_key(cid)
    # í”„ë¦¬í”½ìŠ¤(ìˆìœ¼ë©´)
    if SKIN_PREFIX:
        play_audio_file(SKIN_PREFIX)
    # ë³¸ë¬¸ íŒŒì¼ â†’ ì—†ìœ¼ë©´ í´ë°± TTS
    mp3 = SKIN9_FILES.get(key)
    if not mp3 or not play_audio_file(mp3):
        tts_say_blocking(SKIN9_FALLBACK_TEXT.get(cid, "í”¼ë¶€ ìƒíƒœë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))
    # ì„œí”½ìŠ¤(ìˆìœ¼ë©´)
    if SKIN_SUFFIX:
        play_audio_file(SKIN_SUFFIX)

def print_skin_case_9way(redness_label: str, uniformity_val: float):
    """ì½˜ì†” ì¶œë ¥ë„ 9ê°€ì§€ ê·œì¹™ì— ë§ê²Œ."""
    red = _normalize_redness(redness_label)
    ub  = _uniformity_bucket(uniformity_val)

    # 'ì •ìƒ'ì¼ ë• ê· ì¼ë„ë§Œ ì¶œë ¥
    if red == "ë¶‰ìŒ":
        print("ğŸ“› í”¼ë¶€ê°€ ë‹¤ì†Œ ë¶‰ìŠµë‹ˆë‹¤. í”¼ë¶€ ìê·¹ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”.")
    elif red == "ì°½ë°±":
        print("âš ï¸ í”¼ë¶€ê°€ ì°½ë°±í•´ ë³´ì…ë‹ˆë‹¤. ì»¨ë””ì…˜ ì €í•˜ë‚˜ ìˆ˜ë©´ ë¶€ì¡±ì¼ ìˆ˜ ìˆì–´ìš”.")

    if ub == "ì¢‹ìŒ":
        print("ğŸŸ¢ í”¼ë¶€í†¤ì´ ë§¤ìš° ê· ì¼í•©ë‹ˆë‹¤. ì¢‹ì€ ì»¨ë””ì…˜ì…ë‹ˆë‹¤.")
    elif ub == "ì‚´ì§ ë¶ˆê· ì¼":
        print("âšª í”¼ë¶€í†¤ì´ ì‚´ì§ ë¶ˆê· ì¼í•©ë‹ˆë‹¤. ì•½ê°„ì˜ í”¼ë¡œë‚˜ ê±´ì¡°í•¨ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”.")
    else:
        print("ğŸ¯ í”¼ë¶€í†¤ì´ ë¶ˆê· ì¼í•©ë‹ˆë‹¤. ìƒ‰ì†Œì¹¨ì°©, í”¼ë¡œ ëˆ„ì  ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”.")
            
# === í”¼ë¶€í†¤ íŠ¸ë˜ì»¤ (ë°ê¸°/ë¶‰ê¸°/ê· ì¼ë„/ì¡í‹° + z-score + EMA) ===
class SkinToneTracker:
    def __init__(self, baseline_sec=3, ema_alpha=0.3, fps_hint=30):
        self.N = int(baseline_sec * max(1, fps_hint))
        self.buf_b, self.buf_r = [], []
        self.mu = None
        self.sd = None
        self.a = ema_alpha
        self.sm = dict(b=None, r=None, u=None, bl=None)

    @staticmethod
    def _ema(prev, x, a):
        return x if prev is None else a*x + (1-a)*prev

    @staticmethod
    def _metrics_from_bgr_pixels(bgr_pixels):
        if bgr_pixels.size == 0:
            return 0.0, 1.0, 0.0, 0.0
        px = bgr_pixels.astype(np.float32)
        mb, mg, mr = px[:,0].mean(), px[:,1].mean(), px[:,2].mean()
        m = (mb+mg+mr)/3.0
        kb, kg, kr = m/(mb+1e-6), m/(mg+1e-6), m/(mr+1e-6)
        px[:,0]*=kb; px[:,1]*=kg; px[:,2]*=kr
        px = np.clip(px,0,255)
        B,G,R = px[:,0],px[:,1],px[:,2]
        V = np.max(px,axis=1)
        brightness = float(np.mean(V))
        redness = float((np.mean(R)+1e-6)/(np.mean(G)+1e-6))
        uniformity = float(1.0 - (np.std(V)/255.0))
        uniformity = np.clip(uniformity,0,1)
        thr = np.mean(V)-12.0
        blemish_ratio = float(np.mean((V<thr).astype(np.float32)))
        return brightness, redness, uniformity, blemish_ratio

    def update(self, bgr_pixels):
        b, r, u, bl = self._metrics_from_bgr_pixels(bgr_pixels)
        if self.mu is None:
            self.buf_b.append(b); self.buf_r.append(r)
            if len(self.buf_b) >= self.N:
                mu_b, sd_b = np.mean(self.buf_b), np.std(self.buf_b)+1e-6
                mu_r, sd_r = np.mean(self.buf_r), np.std(self.buf_r)+1e-6
                self.mu, self.sd = np.array([mu_b,mu_r]), np.array([sd_b,sd_r])
        if self.mu is not None:
            z_b = (b-self.mu[0])/self.sd[0]
            z_r = (r-self.mu[1])/self.sd[1]
        else: z_b=z_r=0.0
        self.sm["b"]=self._ema(self.sm["b"],b,self.a)
        self.sm["r"]=self._ema(self.sm["r"],r,self.a)
        self.sm["u"]=self._ema(self.sm["u"],u,self.a)
        self.sm["bl"]=self._ema(self.sm["bl"],bl,self.a)
        tone_lbl = "ë°ìŒ" if z_b>0.7 else ("ì–´ë‘ì›€" if z_b<-0.7 else "ì¤‘ê°„")
        red_lbl  = "í™ì¡°" if z_r>0.8 else ("ì°½ë°±" if z_r<-0.8 else "ì •ìƒ")
        uni_lbl  = "ì–‘í˜¸" if (self.sm["u"] or 0)>=0.8 else ("ë³´í†µ" if (self.sm["u"] or 0)>=0.6 else "ë¶ˆê· ì¼")
        return dict(brightness=self.sm["b"] or 0.0, redness=self.sm["r"] or 1.0,
                    uniformity=self.sm["u"] or 0.0, blemish=self.sm["bl"] or 0.0,
                    z_bright=z_b, z_red=z_r), dict(tone=tone_lbl, redness=red_lbl, uniformity=uni_lbl)

# === POS ê¸°ë°˜ rPPG ì‹ í˜¸ ìƒì„± + í•„í„° ===
def calculate_pos_signal(rgb_values, wG=1.2):
    C = np.asarray(rgb_values,dtype=np.float32)
    mean_rgb = np.mean(C,axis=0)+1e-6
    Cn = C/mean_rgb - 1.0
    S1 = Cn[:,1]-Cn[:,2]
    S2 = Cn[:,1]+Cn[:,2]-2.0*Cn[:,0]
    alpha = np.std(S1)/(np.std(S2)+1e-6)
    return (S1+alpha*S2) - np.mean(S1+alpha*S2)

def bandpass_filter(signal, fs, lowcut=0.7, highcut=3.0, order=3):
    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype='band')
    return filtfilt(b, a, signal)

def speak_skin_feedback_by_files(redness_label: str, uniformity_val: float):
    # 0) ì¸íŠ¸ë¡œ(ìˆìœ¼ë©´)
    if SKIN_FILES.get("intro"):
        play_audio_file(SKIN_FILES["intro"])

    # 1) ë¶‰ê¸° íŒŒíŠ¸
    if redness_label == "ë¶‰ìŒ":
        if not play_audio_file(SKIN_FILES.get("red_high")):
            tts_say_blocking("í”¼ë¶€ê°€ ë‹¤ì†Œ ë¶‰ìŠµë‹ˆë‹¤. í”¼ë¶€ ìê·¹ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”.")
    elif redness_label == "ì°½ë°±":
        if not play_audio_file(SKIN_FILES.get("red_pale")):
            tts_say_blocking("í”¼ë¶€ê°€ ì°½ë°±í•´ ë³´ì…ë‹ˆë‹¤. ì»¨ë””ì…˜ ì €í•˜ë‚˜ ìˆ˜ë©´ ë¶€ì¡±ì¼ ìˆ˜ ìˆì–´ìš”.")
    # 'ì •ìƒ'ì´ë©´ ìƒëµ(ì›í•˜ë©´ ì—¬ê¸°ì„œ ì¶”ê°€ ê°€ëŠ¥)

    # 2) ê· ì¼ë„ íŒŒíŠ¸
    if uniformity_val >= 0.8:
        if not play_audio_file(SKIN_FILES.get("uni_good")):
            tts_say_blocking("í”¼ë¶€í†¤ì´ ë§¤ìš° ê· ì¼í•©ë‹ˆë‹¤. ì¢‹ì€ ì»¨ë””ì…˜ì…ë‹ˆë‹¤.")
    elif 0.6 <= uniformity_val < 0.8:
        if not play_audio_file(SKIN_FILES.get("uni_mid")):
            tts_say_blocking("í”¼ë¶€í†¤ì´ ì‚´ì§ ê· ì¼í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì•½ê°„ì˜ í”¼ë¡œë‚˜ ê±´ì¡°í•¨ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”.")
    else:
        if not play_audio_file(SKIN_FILES.get("uni_low")):
            tts_say_blocking("í”¼ë¶€í†¤ì´ ê³ ë¥´ì§€ ëª»í•´ìš”. ìƒ‰ì†Œì¹¨ì°©, í”¼ë¡œ ëˆ„ì  ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”.")

# === ì˜¤ë””ì˜¤/ë³´ì´ìŠ¤ ì§„ë‹¨ ===
print("[DEBUG] _TTS_DIR:", _TTS_DIR)
print("[DEBUG] end_prefix:", AUDIO_END_PREFIX, "exists:", os.path.exists(AUDIO_END_PREFIX) if AUDIO_END_PREFIX else None)
print("[DEBUG] end_suffix:", AUDIO_END_SUFFIX, "exists:", os.path.exists(AUDIO_END_SUFFIX) if AUDIO_END_SUFFIX else None)
print("[DEBUG] end_fail  :", AUDIO_END_FAIL,   "exists:", os.path.exists(AUDIO_END_FAIL)   if AUDIO_END_FAIL   else None)

print("[DEBUG] macOS?:", platform.system() == "Darwin")
print("[DEBUG] afplay:", shutil.which("afplay") is not None)
print("[DEBUG] say   :", shutil.which("say") is not None)

def _list_korean_voices():
    if shutil.which("say") is None: 
        return []
    try:
        out = subprocess.run(["say","-v","?"], capture_output=True, text=True)
        lines = out.stdout.splitlines()
        return [ln for ln in lines if ("Korean" in ln or "ko_KR" in ln)]
    except Exception as e:
        print("[DEBUG] say -v ? error:", e)
        return []


# In[69]:


# === Baseline ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° + ë¹„êµ/ì§„ë‹¨ ìœ í‹¸ ===
BASELINE_DIR = "baselines"
os.makedirs(BASELINE_DIR, exist_ok=True)

def save_baseline(user_id, baseline_data):
    path = os.path.join(BASELINE_DIR, f"{user_id}.json")
    with open(path,"w",encoding="utf-8") as f:
        json.dump(baseline_data,f,ensure_ascii=False,indent=2)
    print(f"[ì €ì¥ ì™„ë£Œ] {path}")

def load_baseline(user_id):
    path = os.path.join(BASELINE_DIR, f"{user_id}.json")
    if not os.path.exists(path):
        print(f"[ê²½ê³ ] Baseline not found for {user_id}")
        return None
    with open(path,"r",encoding="utf-8") as f:
        return json.load(f)

def compare_to_baseline(current, baseline):
    comp={}
    for k in ["bpm","sdnn","rmssd","brightness","redness","uniformity"]:
        b0, c0 = baseline.get(k), current.get(k)
        if b0 is None or c0 is None: continue
        if k=="bpm":
            z=(c0-b0)/(0.1*b0+1e-6)
            comp["bpm_z"]=z
        else:
            comp[f"{k}_delta"]=(c0-b0)/(b0+1e-6)
    return comp

def diagnose_state(comp):
    bpm_z = comp.get("bpm_z", 0)
    brightness_delta = comp.get("brightness_delta", 0)
    redness_delta = comp.get("redness_delta", 0)
    uniformity_delta = comp.get("uniformity_delta", 0)

    # ì‹¬ë°•ìˆ˜ê°€ ë§ì´ ì¦ê°€í•˜ê³  í”¼ë¶€ ë°ê¸°ê°€ ê°ì†Œí•˜ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ ê°€ëŠ¥ì„±
    if bpm_z > 1.5 and brightness_delta < -0.15:
        return "âš ï¸ ìŠ¤íŠ¸ë ˆìŠ¤ ë˜ëŠ” í˜ˆë¥˜ ì €í•˜ ê°€ëŠ¥"
    # ë¶‰ê¸° ìƒìŠ¹ + ê· ì¼ë„ ì €í•˜ ì‹œ í”¼ë¶€ ê¸´ì¥ or ìˆœí™˜ ë¬¸ì œ
    elif redness_delta > 0.2 and uniformity_delta < -0.15:
        return "âš ï¸ í”¼ë¶€í†¤ ë³€í™” ê°ì§€ë¨"
    elif bpm_z < -1.5:
        return "âš ï¸ ë¹„ì •ìƒì ìœ¼ë¡œ ëŠë¦° ë§¥ë°•"
    else:
        return "ğŸŸ¢ ì•ˆì •ëœ ìƒíƒœ"

# ----- í”¼ë¶€ í”¼ë“œë°± í•¨ìˆ˜  -----
def skin_feedback(tone, redness_label, uniformity_val):
    feedback = []

    #if tone == "ë°ìŒ":
        #feedback.append("â˜€ï¸ í”¼ë¶€ê°€ ë°ì€ ìƒíƒœì…ë‹ˆë‹¤. ì‹¤ë‚´ í™œë™ì´ ë§ê±°ë‚˜ í”¼ë¶€ê°€ ê±´ì¡°í•  ìˆ˜ ìˆì–´ìš”.")     ë³´ë¥˜
    #elif tone == "ì¤‘ê°„":
        #feedback.append("âœ… í”¼ë¶€ ë°ê¸°ëŠ” ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœê°€ ì•ˆì •ì ì´ì—ìš”.")
    #elif tone == "ì–´ë‘ì›€":
        #feedback.append("ğŸŒ í”¼ë¶€ê°€ ì–´ë‘ìš´ í¸ì´ì—ìš”. í–‡ë¹› ë…¸ì¶œì´ ë§ê±°ë‚˜ í”¼ë¡œ ëˆ„ì ì¼ ìˆ˜ ìˆì–´ìš”.")

    if redness_label == "ë¶‰ìŒ":
        feedback.append("ğŸ“› í”¼ë¶€ê°€ ë‹¤ì†Œ ë¶‰ìŠµë‹ˆë‹¤. í”¼ë¶€ ìê·¹ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”.")
    elif redness_label == "ì°½ë°±":
        feedback.append("âš ï¸ í”¼ë¶€ê°€ ì°½ë°±í•´ ë³´ì…ë‹ˆë‹¤. ì»¨ë””ì…˜ ì €í•˜ë‚˜ ìˆ˜ë©´ ë¶€ì¡±ì¼ ìˆ˜ ìˆì–´ìš”.")

    if uniformity_val >= 0.8:
        feedback.append("ğŸŸ¢ í”¼ë¶€í†¤ì´ ë§¤ìš° ê· ì¼í•©ë‹ˆë‹¤. ì¢‹ì€ ì»¨ë””ì…˜ì…ë‹ˆë‹¤.")
    elif 0.6 <= uniformity_val < 0.8:
        feedback.append("âšª í”¼ë¶€í†¤ì´ ì‚´ì§ ê· ì¼í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì•½ê°„ì˜ í”¼ë¡œë‚˜ ê±´ì¡°í•¨ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”.")
    else:
        feedback.append("ğŸ¯ í”¼ë¶€í†¤ì´ ê³ ë¥´ì§€ ëª»í•´ìš”. ìƒ‰ì†Œì¹¨ì°©, í”¼ë¡œ ëˆ„ì  ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”.")

    return "\n".join(feedback)

def show_fft_spectrum(sig, fps):
    # POS ì‹ í˜¸ì— ëŒ€í•œ FFT ê³„ì‚°
    n = len(sig)
    freqs = np.fft.rfftfreq(n, d=1.0/fps)
    fft_vals = np.abs(np.fft.rfft(sig - np.mean(sig)))

    # BPM ë²”ìœ„ë§Œ ì‹œê°í™” (40~180BPM â†’ ì•½ 0.66~3Hz)
    bpm_freq_range = (freqs >= 0.6) & (freqs <= 3.0)
    bpm_freqs = freqs[bpm_freq_range]
    bpm_amplitudes = fft_vals[bpm_freq_range]

    # ì£¼íŒŒìˆ˜ â†’ BPM ë³€í™˜
    bpm_ticks = bpm_freqs * 60

    # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    clear_output(wait=True)
    plt.figure(figsize=(8, 3))
    plt.plot(bpm_ticks, bpm_amplitudes, color='blue')
    plt.title("ì‹¤ì‹œê°„ ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ (BPM ë‹¨ìœ„)")
    plt.xlabel("BPM")
    plt.ylabel("Amplitude")
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# In[72]:


width = 1200
height = 960
fps_hint = 30
last_advice_text = "" 
last_skin_labels = None
last_skin_metrics = None
# ==== ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì¸¡ì • + ê°œì¸í™” ì§„ë‹¨ í†µí•© ====
cam_index = 0  # ì™¸ì¥ ì¹´ë©”ë¼
mirror = 1     # ì¢Œìš°ë°˜ì „ ON
subject = "subject"  # ì‚¬ìš©ì ID ê³ ì •
mode = 0       # 0: ì§„ë‹¨ëª¨ë“œ / 1: Baseline ì €ì¥

BPM_TTS_ENABLE         = True
BPM_TTS_COOLDOWN_SEC   = 10.0
BPM_TTS_DELTA_TO_SPEAK = 3.0
BPM_VALID_RANGE        = (40, 180)

_last_bpm_tts_time = 0.0
_last_bpm_spoken   = None

# baseline ë¶ˆëŸ¬ì˜¤ê¸° + None ë°©ì§€ ì²˜ë¦¬
baseline = load_baseline(subject) if mode == 0 else None
if baseline is None:
    print(f"[ê²½ê³ ] Baseline not found for {subject}")
    baseline = {}

cap = cv2.VideoCapture(cam_index)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
cap.set(cv2.CAP_PROP_FPS, fps_hint)
if not cap.isOpened(): raise RuntimeError("ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨")

skin_tracker = SkinToneTracker(baseline_sec=3, ema_alpha=0.3, fps_hint=fps_hint)
win_sec = 12
rgb_buf = deque(maxlen=fps_hint * win_sec)
t_buf = deque(maxlen=fps_hint * win_sec)
skin_log = []

mp_face_mesh = mp.solutions.face_mesh
LEFT_CHEEK_IDX = [111,117,118,119,120,121,47,126,209,49,203,206,216,214,192,213,177,137,227]
RIGHT_CHEEK_IDX = [340,346,347,348,349,350,277,355,429,279,423,426,436,434,416,433,401,366,447]


with mp_face_mesh.FaceMesh(max_num_faces=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as fm:
    t0 = time.perf_counter(); frame_idx = 0; last_log_time = 0; last_bpm_est = None

    cv2.namedWindow("rPPG+Diagnosis", cv2.WINDOW_NORMAL)
    
    while True:
        ok, img = cap.read()
        if not ok:
            print("[ê²½ê³ ] í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨, 0.5ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(0.5)
            continue
        if mirror: img = cv2.flip(img, 1)
        h, w, _ = img.shape
        res = fm.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        mask = np.zeros((h, w), dtype=np.uint8); cheek_pixels = None

        if res.multi_face_landmarks:
            lm = res.multi_face_landmarks[0]
            lp = [(int(lm.landmark[i].x * w), int(lm.landmark[i].y * h)) for i in LEFT_CHEEK_IDX]
            rp = [(int(lm.landmark[i].x * w), int(lm.landmark[i].y * h)) for i in RIGHT_CHEEK_IDX]
            cv2.fillPoly(mask, [np.array(lp)], 255)
            cv2.fillPoly(mask, [np.array(rp)], 255)
            mb, mg, mr, _ = cv2.mean(img, mask=mask)
            rgb_buf.append([mr, mg, mb]); t_buf.append(time.perf_counter())
            cheek_pixels = cv2.bitwise_and(img, img, mask=mask)[mask == 255]
            cv2.polylines(img, [np.array(lp)], True, (0,255,0), 2)
            cv2.polylines(img, [np.array(rp)], True, (0,255,0), 2)

        now = time.perf_counter()
        if now - t0 > 60:
            print("[INFO] 1ë¶„ ì¸¡ì • ì™„ë£Œ. ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.")
            break
        if cheek_pixels is not None and cheek_pixels.size:
            skin_metrics, skin_labels = skin_tracker.update(cheek_pixels)
            current_metrics = {
                "bpm": last_bpm_est,
                "brightness": skin_metrics["brightness"],
                "redness": skin_metrics["redness"],
                "uniformity": skin_metrics["uniformity"]
            }
            advice_text = skin_feedback(
                tone=skin_labels["tone"],
                redness_label=skin_labels["redness"],
                uniformity_val=skin_metrics["uniformity"]
            )
            last_advice_text = advice_text
            last_skin_labels = skin_labels
            last_skin_metrics = skin_metrics

            if mode == 0 and baseline:
                comp = compare_to_baseline(current_metrics, baseline)
                diagnosis = diagnose_state(comp)
            else:
                diagnosis = "ê¸°ì¤€ ì €ì¥ ì¤‘"

            if now - last_log_time >= 1.0:
                last_log_time = now
                print(f"[{int(now - t0)}s] Tone:{skin_labels['tone']} Red:{skin_labels['redness']} BPM:{last_bpm_est}")
                print(f" >> ìƒíƒœ ì§„ë‹¨: {diagnosis}")  # âœ… ì´ê±° ì¶”ê°€!
                skin_log.append({
                    "time_sec": now - t0, "bpm": last_bpm_est,
                    "brightness": skin_metrics["brightness"],
                    "redness": skin_metrics["redness"],
                    "uniformity": skin_metrics["uniformity"],
                    "diagnosis": diagnosis
                })

            cv2.putText(img, f"State: {diagnosis}", (12, 132), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            cv2.putText(img, f"State: {diagnosis}", (12, 132), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)

        if len(rgb_buf) >= int(fps_hint * 8):
            t_arr = np.array(t_buf)
            fs = 1.0 / np.median(np.diff(t_arr))
            pos = calculate_pos_signal(np.array(rgb_buf))
            fpos = bandpass_filter(pos, fs=fs, lowcut=0.7, highcut=3.0)
            freqs = np.fft.rfftfreq(len(fpos), 1 / fs)
            mag = np.abs(np.fft.rfft(fpos))
            valid = (freqs >= 0.8) & (freqs <= 3.0)
            if np.any(valid):
                peak = freqs[valid][np.argmax(mag[valid])]
                new_bpm = peak * 60

                # ==== íŠ ë°©ì§€ ì¡°ê±´ ì¶”ê°€ ====
                if last_bpm_est is not None:
                    if abs(new_bpm - last_bpm_est) > 0.25 * last_bpm_est:
                        new_bpm = last_bpm_est  # ë³€í™” í­ ë„ˆë¬´ í¬ë©´ ì´ì „ BPM ìœ ì§€
                last_bpm_est = new_bpm
               
        cv2.imshow("rPPG+Diagnosis", img)
        if cv2.waitKey(1) & 0xFF == 27: break


    cap.release()
    cv2.destroyWindow("rPPG+Diagnosis")
    cv2.waitKey(100)

# ---- ì¢…ë£Œ í›„ baseline ì €ì¥ ----
if mode == 1 and len(skin_log) > 0:
    avg_vals = pd.DataFrame(skin_log).mean(numeric_only=True).to_dict()
    baseline_data = dict(
        bpm=avg_vals.get("bpm", np.nan),
        brightness=avg_vals.get("brightness", 0),
        redness=avg_vals.get("redness", 1),
        uniformity=avg_vals.get("uniformity", 0)
    )
    save_baseline(subject, baseline_data)
    print(f"[ì €ì¥ ì™„ë£Œ] baselines/{subject}.json")

# ---- ì¢…ë£Œ ìš”ì•½ ----
if len(rgb_buf) >= int(fps_hint * 10):
    df = pd.DataFrame(skin_log)
    print("\n[ì¸¡ì • ìš”ì•½ ê²°ê³¼]")
    print(f" - í‰ê·  BPM        : {df['bpm'].mean():.2f}")
    print(f" - í‰ê·  ë°ê¸°        : {df['brightness'].mean():.3f}")
    print(f" - í‰ê·  ë¶‰ê¸°        : {df['redness'].mean():.3f}")
    print(f" - í‰ê·  ê· ì¼ë„      : {df['uniformity'].mean():.3f}")

    final_bpm = None
    if 'bpm' in df and df['bpm'].notna().sum() > 0:
        final_bpm = float(df['bpm'].mean())
    elif last_bpm_est is not None:
        final_bpm = float(last_bpm_est)

    if final_bpm is not None and 40 <= final_bpm <= 180:
        ok1 = play_audio_file(AUDIO_END_PREFIX) if AUDIO_END_PREFIX else False
        
        num_spoken = tts_say_blocking(f"{int(round(final_bpm))}")  # ìˆ«ìë§Œ TTS
        if not num_spoken:
            print("[WARN] ìˆ«ì TTS ì‹¤íŒ¨. (ë³´ì´ìŠ¤ ë¯¸ì„¤ì¹˜/ê¶Œí•œ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ)")
        
        ok3 = play_audio_file(AUDIO_END_SUFFIX) if AUDIO_END_SUFFIX else False
        
        # ìµœì†Œí•œ ë­”ê°€ëŠ” ë‚˜ì™”ëŠ”ì§€ í™•ì¸ (ëª¨ë‘ ì‹¤íŒ¨ë¼ë©´ ë§ˆì§€ë§‰ í´ë°±)
        if not (ok1 or num_spoken or ok3):
            # 'say'ê°€ ì•„ì˜ˆ ë¶ˆê°€ë©´ ì´ í´ë°±ë„ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ì—¬ê¸°ì„œëŠ” mp3ë§Œ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë¡œê·¸ë§Œ ë‚¨ê¸°ë„ë¡ ì„ íƒ
            print("[FALLBACK] ì˜¤ë””ì˜¤ ì¬ìƒ ì „ë¶€ ì‹¤íŒ¨. íŒŒì¼ëª…/ê²½ë¡œ/ë³´ì´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        if not play_audio_file(AUDIO_END_FAIL):
            tts_say_blocking("ì¸¡ì •ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì‹¬ë°•ìˆ˜ ë°ì´í„°ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
    # ==== í”¼ë¶€ í”¼ë“œë°±: 9ê°€ì§€ ì¼€ì´ìŠ¤ ê·œì¹™ìœ¼ë¡œ ì¶œë ¥ + íŒŒì¼ìš°ì„ (TTSí´ë°±) ì•ˆë‚´ ====
    if last_skin_labels and last_skin_metrics:
        print("\n[í”¼ë¶€ í”¼ë“œë°±]")
        print_skin_case_9way(
            redness_label=last_skin_labels["redness"],
            uniformity_val=float(last_skin_metrics["uniformity"] or 0.0)
        )
        # ìŒì„± ì¶œë ¥(íŒŒì¼ ì—†ìœ¼ë©´ ìë™ TTS)
        speak_skin_case_9way(
            redness_label=last_skin_labels["redness"],
            uniformity_val=float(last_skin_metrics["uniformity"] or 0.0)
        )

    # âœ… ìµœì¢… ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ (ì‹¬ë°•ìˆ˜ ì¶”ì •ìš©)
    print("\n[ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼]")
    t_arr = np.array(t_buf)
    fs = 1.0 / np.median(np.diff(t_arr))
    pos = calculate_pos_signal(np.array(rgb_buf))
    fpos = bandpass_filter(pos, fs=fs, lowcut=0.7, highcut=3.0)
    freqs = np.fft.rfftfreq(len(fpos), 1 / fs)
    mag = np.abs(np.fft.rfft(fpos))
    valid = (freqs >= 0.8) & (freqs <= 3.0)

    plt.figure(figsize=(10, 4))
    plt.plot(freqs[valid], mag[valid], color='tab:blue')
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("d")
    plt.title("Spectrum")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    
else:
    print("\n[ì•Œë¦¼] ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ 10ì´ˆ ë¯¸ë§Œì´ë¼ ê²°ê³¼ ìš”ì•½ì„ ìƒëµí•©ë‹ˆë‹¤.")

